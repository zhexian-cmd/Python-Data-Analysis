{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7de4fc-be70-45f8-ba25-f6ffd8e6aa95",
   "metadata": {},
   "source": [
    "# 第一步：导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab588f7-1348-42c3-afbb-c9d409283327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3d01e-7a05-4902-8309-a650b83caed9",
   "metadata": {},
   "source": [
    "# 第二步：读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913bdc5-1ec9-433b-864f-2741045aa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_file = pd.read_csv(\" \")\n",
    "# original_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b5a13-34fb-4ba8-ae05-ac0411eeda45",
   "metadata": {},
   "source": [
    "# 第三步：评估数据  \n",
    "\n",
    "在这一部分中，我们将对在上一部分建立的original_file DataFrame所包含的数据进行评估和清理。  \n",
    "\n",
    "主要从两个方面进行：结构和内容，即整齐度和干净度。  \n",
    "\n",
    "数据的结构性问题指不符合“每个变量为一列，每个观察值为一行，每种类型的观察单位为一个表格”这三个标准；数据的内容性问题包括存在丢失数据、重复数据、无效数据等。  \n",
    "\n",
    "为了区分开经过清理的数据和原始的数据，我们创建新的变量cleaned_file，让它为original_file复制出的副本。我们之后的清理步骤都将被运用在cleaned_file上。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b965f-f77d-48ea-8ad6-bb3e2992cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file = original_file.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b265da5-29d1-4aba-a424-54eda5e665b3",
   "metadata": {},
   "source": [
    "数据整齐度（即每个变量为一列，每个观察值为一行，每种类型的观察单位为一个表格）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd92d711-11ce-4517-a814-7491d7c85647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833e5ff-3613-4c52-952e-1bbfe298200f",
   "metadata": {},
   "source": [
    "数据干净度（用info进行初步观察）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518e841-6714-4bf4-b045-ad7bc96e0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46449a66-2cb4-43a0-904c-6f4ec169546f",
   "metadata": {},
   "source": [
    "从输出结果来看，找到存在缺失值的变量名，将在后续进行评估和清理。\n",
    "\n",
    "从数据类型来看，应对某些类型的数据进行类型转换。\n",
    "\n",
    "同时分类数据都应转换成Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ed6a3-9001-4603-aa68-09fb2eaa0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file['列名'] = cleaned_file['前面的列名'].astype('数据类型')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454f64c-749c-4602-a258-e7e68dc50e4b",
   "metadata": {},
   "source": [
    "再次通过info查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02c250b-569a-44fc-afc2-864c03e7de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154296c6-8d8b-43e0-a032-633308a235be",
   "metadata": {},
   "source": [
    "# 第四步：处理缺失数据\n",
    "\n",
    "看NaN的值有多少，即为有多少缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d79f9e-6200-4245-bc6d-8542d1d30373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file[cleaned_file['缺数据的列名'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d16fe-d135-465c-a746-f0fb5b47e3b9",
   "metadata": {},
   "source": [
    "处理缺失值方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e012a7-b702-4fff-acf2-0a9e0e2b03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_data = cleaned_file['缺数据的列名'].mean()   算平均数\n",
    "# cleaned_file['缺数据的列名'] = cleaned_file['缺数据的列名'].fillna(average_data) 将缺失值用平均数替换\n",
    "#cleaned_file['缺数据的列名'].isna().sum()        如果显示0，则处理完成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb06bd5-47e5-4bdc-886f-b2fb95863cea",
   "metadata": {},
   "source": [
    "# 第五步：处理重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240dabe7-e395-49aa-beb7-698fac5947c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file[\"重复变量名\"].duplicated().sum()   输出结果应为0，否则表示有重复值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bb9ee-4b5c-4235-a565-90daee8df951",
   "metadata": {},
   "source": [
    "# 第六步：处理不一致数据\n",
    "\n",
    "不一致数据可能存在于所有分类变量中，我们要查看是否存在不同值实际指代同一目标的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791714dc-0140-4413-9404-894fb7022533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file[\"变量名\"].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc789d0d-4659-432b-bf21-7b531801131c",
   "metadata": {},
   "source": [
    "# 第七步：处理无效或错误数据\n",
    "\n",
    "可以先通过DataFrame的describe（）方法，对数值统计信息进行快速了解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0827e1af-c179-489e-b8b4-aaf6ce8b93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222e9dd-219a-4e12-8d99-08b49092c9f0",
   "metadata": {},
   "source": [
    "# 第八步：整理数据\n",
    "\n",
    "包括将一些变量名进行合并，拆分等操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758b204f-e606-40b0-9b49-8b94a14447c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_file['合并后的变量名'] = cleaned_file['变量名1'] + cleaned_file['变量名2']\n",
    "# cleaned_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797bd8fc-07ab-4d84-9b85-98b476586fe2",
   "metadata": {},
   "source": [
    "探索数据\n",
    "\n",
    "在着手逻辑回归分析之前，我们可以先借助数据可视化，探索数值变量的分布，以及与乘客是否幸存存在相关性的变量，为后续的进一步分析提供方向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32cdebbd-6418-4ae2-b132-e6df0c4170a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图表色盘为\"pastel\"，也可以是其他色盘\n",
    "# sns.set_palette(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa5af7-9237-4ad2-a0b0-bd9694cf8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图表尺寸，不同尺寸都可以，取汝之喜好即可\n",
    "# plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "# plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b481b2b-944f-46ad-ac97-43bbe5d981a8",
   "metadata": {},
   "source": [
    "绘制饼图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8007ce-41e6-41b5-bb0c-6699379e7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1_count = cleaned_file['变量名'].value_counts()\n",
    "# data2_label = data1.index\n",
    "# plt.pie(data1_count, labels=data2_label, autopct='%.1f%%')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdbb634-aaf3-41c6-a8ca-346f217e6de4",
   "metadata": {},
   "source": [
    "绘制直方图和箱式图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7d979-46f3-46fb-bf53-471a88cae9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure, axes = plt.subplots(1, 2)\n",
    "# sns.histplot(cleaned_file, x='变量名', ax=axes[0])\n",
    "# sns.boxplot(cleaned_file, y='变量名', ax=axes[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7919c8d-f6b3-4e95-a4f2-a6e3b77a6425",
   "metadata": {},
   "source": [
    "# 第九步：分析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d2e0fa-954f-4dab-a9e0-b1bfb7e4f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f0cab-cae1-426d-bc53-fd65b3adda00",
   "metadata": {},
   "source": [
    "然后可以创建一个新的DataFrame lr_file，让它作为我们进逻辑性回归分析所用的数据。\n",
    "\n",
    "和cleaned_file区分开的原因是，我们在进行回归分析前，还可能需要对数据进行一些准备。\n",
    "\n",
    "比如引入虚拟变量，这些都可以在lr_file上执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adca3cd2-63ba-4464-89d8-fd1f893f7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_file = cleaned_file.copy()   备份\n",
    "# lr_file.head()                  初步观察"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92659d1d-dc54-4b20-a1d9-3d4c9ff18cca",
   "metadata": {},
   "source": [
    "移除大概率不会影响研究的变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49aef3da-2913-4a7d-8d54-e8dc9a3a9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_file = lr_file.drop(['无关变量1', '无关变量2', '无关变量3', ......, '无关变量n'], axis=1)\n",
    "# lr_file.head()    观察删除后的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3317da6-c6a9-4db1-aaa5-8c88bbf451c3",
   "metadata": {},
   "source": [
    "数据里还存在分类变量，无法直接建立逻辑回归模型。我们需要引入虚拟变量，也就是用0和1分别表示是否属于该类别。\n",
    "\n",
    "用get_dummies方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1909c18e-8ccf-46a0-afd5-24a10008f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_file = pd.get_dummies(lr_file, drop_first=True, columns=['分类变量1', ...... , '分类变量n'], dtype=int)\n",
    "# lr_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a111f-0aa2-4942-a6d0-c704f2e49c90",
   "metadata": {},
   "source": [
    "接下来，我们要把因变量（y）和自变量（x）划分出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4941ba-b63c-4114-af44-9763039be5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = lr_file['因变量的列名']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53058f7-dd76-4d7d-8a38-87f63be6fe46",
   "metadata": {},
   "source": [
    "我们可以把除 '因变量对应列名' 之外的先纳入自变量，但需要查看它们之间的相关性。\n",
    "\n",
    "如果其中有些变量之间相关性很高，会导致共线性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30c93b-f465-4a71-8f5a-b32e6dab3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = lr_file.drop(['Survived'], axis=1)  这里用drop方法将因变量的列名删除后，其余列名赋值成自变量\n",
    "# X.corr()      用corr方法观察自变量之间的相关性强弱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf99b2-187a-4a1b-84ad-2c9fc1687e9f",
   "metadata": {},
   "source": [
    "一般我们认为，当相关系数的绝对值大于0.8的时候，可能导致严重共线性，所以我们检查的时候，找绝对值大于0.8的值即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cb389-5241-46b2-91df-c2afcbd13b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.corr().abs() > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca07b9-f2fa-4f71-98b8-d839a15e831c",
   "metadata": {},
   "source": [
    "不同变量之间的如果相关性过高，会导致数值优化算法无法收敛，无法获得逻辑回归模型参数的计算结果。\n",
    "\n",
    "此外，需仔细看相关系数数值，如果某些自变量的相关系数接近0.8，也应对其进行移除，避免算法无法收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d3b726-3d9d-48bb-9cc1-3721ce9a2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(['自变量1', ...... , '自变量n'], axis=1)  删除相关性过高的自变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b1d49-515c-42ff-8e2c-309495e2eef8",
   "metadata": {},
   "source": [
    "接下来，给模型的线性方程添加截距。\n",
    "\n",
    "用sm库里面的add_constant函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c28bb79-5b94-40e0-b107-88b04d0b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948004bc-1ad9-45f5-921f-40c77a7fcad4",
   "metadata": {},
   "source": [
    "下一步就可以调用Logit函数，利用最大似然优化来得到逻辑回归模型的参数值，并输出总结信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c0ed4-a2f9-4082-b2c4-ea5ec3758184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = sm.Logit(y, X).fit()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718f665-fabf-472a-b1aa-eefb409c5e20",
   "metadata": {},
   "source": [
    "当我们把显著区间设定为0.05时，以上结果的P值，如果发现某个自变量对研究无影响（即P值大于0.05）时，应该把这个变量移除后，再次建立逻辑回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfac487-a457-41f8-babf-69825e0fb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(['无影响的变量名'], axis=1)\n",
    "# model = sm.Logit(y, X).fit()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be13c57-625d-4b8c-861e-cf0caf070c2a",
   "metadata": {},
   "source": [
    "要理解各个各个自变量系数的实际含义，我们需要计算自然常数的次方。\n",
    "\n",
    "直接用numpy库里面的exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617ee66-9abe-42ec-a4af-a2e6ede1423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.exp(系数)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31d04a-a051-44f4-84c9-95a6a9328738",
   "metadata": {},
   "source": [
    "# 第十步：根据模型推数据\n",
    "根据样本数据建立模型后，我们就可以用此模型去推其他数据啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066d9b14-4efc-4128-8a03-50b40eb17556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = pd.read_csv(\"想要预测数据的文件\")\n",
    "# data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5925a-8290-49fd-8173-643f7c497dcd",
   "metadata": {},
   "source": [
    "由于逻辑回归模型不允许数据中有缺失值，因此我们需要检查data_test是否存在数据缺失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25e80b18-7525-4019-9bb6-c8d188ea283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2308d11-2df5-4427-95e9-7dcee4108004",
   "metadata": {},
   "source": [
    "缺失值若不属于回归模型的自变量，可以忽略\n",
    "\n",
    "若属于回归模型的自变量，可以用平均值进行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce05521-c34b-4983-87fb-69a6a59f8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test['缺数据的变量名'] = data_test['缺数据的变量名'].fillna(data_test['缺数据的变量名'].mean())\n",
    "# data_test['缺数据的变量名'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cf68a-fa10-4435-b86f-89f954ce7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "下一步是给模型中的分类变量引入虚拟变量，但在引入前我们需要先把分类变量的类型转换为Category，并且通过categories参数，让程序知道所有可能的分类值。\n",
    "\n",
    "这样做的原因是，预测数据包含的分类可能不全。我们需要确保引入虚拟变量的时候，不会漏掉某个或某些分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e0ce1bf-6d97-4c11-b659-134f58fe4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test['分类变量1'] = pd.Categorical(data_test['分类变量1'], categories=[所有类型])\n",
    "# data_test['分类变量2'] = pd.Categorical(data_test['分类变量2'], categories=[所有类型])\n",
    "# data_test['分类变量n'] = pd.Categorical(data_test['分类变量3'], categories=[所有类型])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c31b5e-7954-4301-94f3-258f1376ab1d",
   "metadata": {},
   "source": [
    "下一步，给模型用到的分类变量引入虚拟变量。\n",
    "\n",
    "还是get_dummies方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e656f3-201a-461e-9e91-2f4de5d0aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = pd.get_dummies(data_test, drop_first=True, columns=['分类变量1', ......, '分类变量n'], dtype=int)\n",
    "# data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709baee-75f5-4019-9e90-968049aa2b40",
   "metadata": {},
   "source": [
    "查看一下模型需要的输入变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951b226-2a57-4eac-bf63-99fdaa5f5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a334837-4048-4db7-af51-ab30795a4758",
   "metadata": {},
   "source": [
    "接下来构建我们要输入给模型进行预测的变量，需要和模型训练时的输入一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a87fad-c0f5-4d4d-9525-7dd3789df328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = data_test[[......]]\n",
    "# X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817ba96-4110-41a7-91b7-7fecb26a7eeb",
   "metadata": {},
   "source": [
    "现在就可以调用逻辑回归模型的predict方法，获得预测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf169815-4dfc-400a-9d43-f9df4d4a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_value = model.predict(X_test)\n",
    "# predicted_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
